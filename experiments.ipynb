{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1t1zuq75n0kcKBD6uGKvNhN-AkdYokvqM","timestamp":1733396998824}],"gpuType":"V28","authorship_tag":"ABX9TyO5BQWAV8RN9U2cQE2HSbBj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["런타임 > 런타임 유형 변경 > TPU v2-8으로 변경 후 코드 실행"],"metadata":{"id":"1briftkvi4LC"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yaD_1LPPdX00","executionInfo":{"status":"ok","timestamp":1734678299824,"user_tz":-540,"elapsed":17413,"user":{"displayName":"손정우","userId":"14800842552973262426"}},"outputId":"164587f6-38ad-4fce-f235-7f6a742e3596"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"markdown","source":["Clone our code from GitHub if it does not exist."],"metadata":{"id":"M_BjHj00B377"}},{"cell_type":"code","source":["import os\n","dataset_name = 'test'\n","if not os.path.exists('/content/drive/MyDrive/DS535'):\n","  os.mkdir('/content/drive/MyDrive/DS535')\n","os.chdir('/content/drive/MyDrive/DS535')\n","if not os.path.exists(dataset_name):\n","  os.mkdir(dataset_name)\n","os.chdir(dataset_name)"],"metadata":{"id":"qOubiUVO4aoQ","executionInfo":{"status":"ok","timestamp":1734678374808,"user_tz":-540,"elapsed":419,"user":{"displayName":"손정우","userId":"14800842552973262426"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["if not os.path.exists('DS535_Team3'):\n","  !git clone https://github.com/anminhyeong/DS535_Team3.git"],"metadata":{"id":"EDQVdlNCg6aD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734678388439,"user_tz":-540,"elapsed":1404,"user":{"displayName":"손정우","userId":"14800842552973262426"}},"outputId":"1f8a6a9e-5d94-42e7-c9bd-ffbdf161fc81"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'DS535_Team3'...\n","remote: Enumerating objects: 117, done.\u001b[K\n","remote: Counting objects: 100% (117/117), done.\u001b[K\n","remote: Compressing objects: 100% (87/87), done.\u001b[K\n","remote: Total 117 (delta 65), reused 58 (delta 25), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (117/117), 35.20 KiB | 924.00 KiB/s, done.\n","Resolving deltas: 100% (65/65), done.\n"]}]},{"cell_type":"code","source":["os.chdir('DS535_Team3')"],"metadata":{"id":"49WjMYC_dgIR","executionInfo":{"status":"ok","timestamp":1734678396615,"user_tz":-540,"elapsed":310,"user":{"displayName":"손정우","userId":"14800842552973262426"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Install packages."],"metadata":{"id":"4K8Jp1R1CEEe"}},{"cell_type":"code","source":["!pip install -U \"jax[tpu]==0.4.23\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n","!pip install scipy==1.11.2\n","!pip install torch_geometric==2.3.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"sYmha_B8-ZnB","executionInfo":{"status":"ok","timestamp":1734678440031,"user_tz":-540,"elapsed":14102,"user":{"displayName":"손정우","userId":"14800842552973262426"}},"outputId":"63e26d7a-8648-4048-abe2-3dfcb837d906"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scipy==1.11.2\n","  Downloading scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy==1.11.2) (1.26.4)\n","Downloading scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.13.1\n","    Uninstalling scipy-1.13.1:\n","      Successfully uninstalled scipy-1.13.1\n","Successfully installed scipy-1.11.2\n","Collecting torch_geometric==2.3.1\n","  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.3.1) (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.3.1) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.3.1) (1.11.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.3.1) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.3.1) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.3.1) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.3.1) (1.6.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.3.1) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.3.1) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.3.1) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.3.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.3.1) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.3.1) (2024.12.14)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.3.1) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.3.1) (3.5.0)\n","Building wheels for collected packages: torch_geometric\n","  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910447 sha256=3f2da7172796b51780b58b94073291b8e4cd2b0209a7ce37718bd875fab88bcb\n","  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n","Successfully built torch_geometric\n","Installing collected packages: torch_geometric\n","Successfully installed torch_geometric-2.3.1\n"]}]},{"cell_type":"markdown","source":["We conducted experiments differentiating the following settings:\n","1. Random walk strategies (random walk, DFS-like walk, highly DFS-like walk)\n","  - Configured as argument (p_value and q_value) in the preprocess.py command.\n","  - Random walk: p_value = 1.0, q_value = 1.0\n","  - DFS-like walk: p_value = 1e10, q_value = 0.5\n","  - Highly DFS-like walk: p_value = 1e10, q_value = 0.1\n","2. Mask data type (int, bool)\n","  - Configured as argument (bool_mask) in the preprocess.py command.\n","3. Number of hops (num_hops = 3, 4, 5)\n","  - Configured as argument (num_hops) in the train_{pixel, sbm, zinc}.py command."],"metadata":{"id":"hXSbtzY6_YU9"}},{"cell_type":"markdown","source":["Instead of executing preprocess.py in Colab, we executed it in local environment and uploaded the dataset files (npy and npz) to the corresponding folder given below.\n","- MNIST: ./data/MNIST\n","- CIFAR10: ./data/CIFAR10\n","- CLUSTER: ./data/CLUSTER\n","- PATTERN: ./data/PATTERN\n","- ZINC: ./data/ZINC/subset\n","\n","Or you can download the dataset from the following link.\n","\n","https://drive.google.com/drive/folders/12kKq-WAer7TYh3R5H3wyxzZaWTqzyOyD?usp=drive_link"],"metadata":{"id":"DnWBf-RXiXm_"}},{"cell_type":"code","source":["# !python preprocess.py --length 5 --num 5 --p_value 1.0 --q_value 1.0 --name MNIST"],"metadata":{"id":"TKmnvVdw3v-V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To apply a boolean mask when running the train_{pixel, sbm, zinc}.py command, you need to include the --bool_mask argument in your command."],"metadata":{"id":"YGXVDnlJ8xvl"}},{"cell_type":"code","source":["# !python train_pixel.py --name MNIST --num_layers 4 --num_hops 3 --dim_h 128 --dim_v 96\n","# !python train_pixel.py --name CIFAR10 --num_layers 8 --num_hops 5 --dim_h 96 --dim_v 64\n","# !python train_sbm.py --name CLUSTER --num_layers 16 --dim_h 64 --dim_v 64 --weight_decay 0.2 --r_min 0.9\n","# !python train_sbm.py --name PATTERN --num_layers 10 --dim_h 72 --dim_v 64 --weight_decay 0.1 --r_min 0.5\n","!python train_zinc.py --bool_mask"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MQLSM73v-YRM","outputId":"3278da60-adfa-4929-dd27-936895676296"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(num_layers=11, num_hops=5, dim_h=72, dim_v=72, r_min=0.9, r_max=1.0, max_phase=6.28, drop_rate=0.2, expand=1, act='full-glu', bool_mask=True, lr_min=1e-07, lr_max=0.001, weight_decay=0.1, lr_factor=1.0, epochs=2000, batch_size=32, warmup=0.05, seed=0, gpu='0', length_walk=5, num_walk=5, p_value=1.0, q_value=1.0)\n","/content/drive/MyDrive/DS535/test/DS535_Team3/train_zinc.py:60: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n","For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n","  key: random.KeyArray\n","E1220 07:11:28.438127977    8215 oauth2_credentials.cc:176]            Call to http server ended with error 404 [].\n","# parameters: 483049\n","train size: 10000; # train steps per epoch: 312; # train steps total: 624000\n","val size: 1000; # val steps: 32\n","test size: 1000; # test steps: 32\n","/usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:2660: ComplexWarning: Casting complex values to real discards the imaginary part\n","  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n","Epoch: 1; Training loss: 3.4838199615478516\n","Epoch: 1; Val loss: 1.5153168439865112\n","Time per epoch: 84.61149978637695 seconds\n","Epoch: 2; Training loss: 2.3964731693267822\n","Epoch: 2; Val loss: 1.0389199256896973\n","Time per epoch: 7.8729941844940186 seconds\n","Epoch: 3; Training loss: 1.7554205656051636\n","Epoch: 3; Val loss: 0.8774439692497253\n","Time per epoch: 7.844285488128662 seconds\n","Epoch: 4; Training loss: 1.458999514579773\n","Epoch: 4; Val loss: 1.578467607498169\n","Time per epoch: 7.651391983032227 seconds\n","Epoch: 5; Training loss: 1.2470216751098633\n","Epoch: 5; Val loss: 1.5754117965698242\n","Time per epoch: 7.665969610214233 seconds\n","Epoch: 6; Training loss: 1.0753529071807861\n","Epoch: 6; Val loss: 1.6377992630004883\n","Time per epoch: 7.651588201522827 seconds\n","Epoch: 7; Training loss: 1.0215157270431519\n","Epoch: 7; Val loss: 1.1683709621429443\n","Time per epoch: 7.66883397102356 seconds\n","Epoch: 8; Training loss: 0.907024085521698\n","Epoch: 8; Val loss: 0.6211126446723938\n","Time per epoch: 7.8338541984558105 seconds\n","Epoch: 9; Training loss: 0.8866367936134338\n","Epoch: 9; Val loss: 0.6001099944114685\n","Time per epoch: 7.806163549423218 seconds\n","Epoch: 10; Training loss: 0.8196083307266235\n","Epoch: 10; Val loss: 0.6354569792747498\n","Time per epoch: 7.646658182144165 seconds\n","Epoch: 11; Training loss: 0.8210131525993347\n","Epoch: 11; Val loss: 0.7121928334236145\n","Time per epoch: 7.665050506591797 seconds\n","Epoch: 12; Training loss: 0.7333113551139832\n","Epoch: 12; Val loss: 0.699126124382019\n","Time per epoch: 7.650429725646973 seconds\n","Epoch: 13; Training loss: 0.751652181148529\n","Epoch: 13; Val loss: 0.5728683471679688\n","Time per epoch: 7.663842439651489 seconds\n","Epoch: 14; Training loss: 0.7703477144241333\n","Epoch: 14; Val loss: 0.7109624743461609\n","Time per epoch: 7.65094780921936 seconds\n","Epoch: 15; Training loss: 0.7429397106170654\n","Epoch: 15; Val loss: 0.6640518307685852\n","Time per epoch: 7.830639600753784 seconds\n","Epoch: 16; Training loss: 0.7654344439506531\n","Epoch: 16; Val loss: 0.8986788988113403\n","Time per epoch: 7.648396015167236 seconds\n","Epoch: 17; Training loss: 0.7500851154327393\n","Epoch: 17; Val loss: 0.6763949394226074\n","Time per epoch: 7.819195985794067 seconds\n","Epoch: 18; Training loss: 0.6637211441993713\n","Epoch: 18; Val loss: 0.627128005027771\n","Time per epoch: 7.64986252784729 seconds\n","Epoch: 19; Training loss: 0.6783223152160645\n","Epoch: 19; Val loss: 0.5880886316299438\n","Time per epoch: 7.659324884414673 seconds\n","Epoch: 20; Training loss: 0.6574814319610596\n","Epoch: 20; Val loss: 0.5787366032600403\n","Time per epoch: 7.817256689071655 seconds\n","Epoch: 21; Training loss: 0.7013518810272217\n","Epoch: 21; Val loss: 0.6157289743423462\n","Time per epoch: 7.661535024642944 seconds\n","Epoch: 22; Training loss: 0.6316470503807068\n","Epoch: 22; Val loss: 0.8493265509605408\n","Time per epoch: 7.73537278175354 seconds\n","Epoch: 23; Training loss: 0.6302377581596375\n","Epoch: 23; Val loss: 0.8803013563156128\n","Time per epoch: 7.661261796951294 seconds\n","Epoch: 24; Training loss: 0.6287460327148438\n","Epoch: 24; Val loss: 0.5993120074272156\n","Time per epoch: 7.652134418487549 seconds\n","Epoch: 25; Training loss: 0.633935272693634\n","Epoch: 25; Val loss: 0.5954828858375549\n","Time per epoch: 7.8528594970703125 seconds\n","Epoch: 26; Training loss: 0.6188980340957642\n","Epoch: 26; Val loss: 0.7103984951972961\n","Time per epoch: 7.8061394691467285 seconds\n","Epoch: 27; Training loss: 0.5904321074485779\n","Epoch: 27; Val loss: 0.5694634914398193\n","Time per epoch: 7.664011240005493 seconds\n","Epoch: 28; Training loss: 0.5864552855491638\n","Epoch: 28; Val loss: 0.5730981826782227\n","Time per epoch: 7.651847839355469 seconds\n","Epoch: 29; Training loss: 0.5970785021781921\n","Epoch: 29; Val loss: 0.5379066467285156\n","Time per epoch: 7.662876605987549 seconds\n","Epoch: 30; Training loss: 0.583819568157196\n","Epoch: 30; Val loss: 0.7203434109687805\n","Time per epoch: 7.650477170944214 seconds\n","Epoch: 31; Training loss: 0.620209813117981\n","Epoch: 31; Val loss: 0.5368921756744385\n","Time per epoch: 7.664401292800903 seconds\n","Epoch: 32; Training loss: 0.5691785216331482\n","Epoch: 32; Val loss: 0.7634784579277039\n","Time per epoch: 7.8531858921051025 seconds\n","Epoch: 33; Training loss: 0.5699413418769836\n","Epoch: 33; Val loss: 0.5662814378738403\n","Time per epoch: 7.812201261520386 seconds\n","Epoch: 34; Training loss: 0.5473885536193848\n","Epoch: 34; Val loss: 0.5711676478385925\n","Time per epoch: 7.647485017776489 seconds\n","Epoch: 35; Training loss: 0.5472297668457031\n","Epoch: 35; Val loss: 0.5393657684326172\n","Time per epoch: 7.6622679233551025 seconds\n","Epoch: 36; Training loss: 0.5404942631721497\n","Epoch: 36; Val loss: 0.5079360008239746\n","Time per epoch: 7.649634599685669 seconds\n","Epoch: 37; Training loss: 0.5443762540817261\n","Epoch: 37; Val loss: 0.5098727941513062\n","Time per epoch: 7.85407280921936 seconds\n","Epoch: 38; Training loss: 0.5424119234085083\n","Epoch: 38; Val loss: 0.6202451586723328\n","Time per epoch: 7.801704168319702 seconds\n","Epoch: 39; Training loss: 0.5258713364601135\n","Epoch: 39; Val loss: 0.5644586086273193\n","Time per epoch: 7.660796642303467 seconds\n","Epoch: 40; Training loss: 0.510368824005127\n","Epoch: 40; Val loss: 0.4952649474143982\n","Time per epoch: 7.653744220733643 seconds\n","Epoch: 41; Training loss: 0.519966721534729\n","Epoch: 41; Val loss: 0.5398029685020447\n","Time per epoch: 7.6556384563446045 seconds\n","Epoch: 42; Training loss: 0.5091464519500732\n","Epoch: 42; Val loss: 0.6027430891990662\n","Time per epoch: 7.64035439491272 seconds\n","Epoch: 43; Training loss: 0.4965386986732483\n","Epoch: 43; Val loss: 0.49632078409194946\n","Time per epoch: 7.828831672668457 seconds\n","Epoch: 44; Training loss: 0.4940205514431\n","Epoch: 44; Val loss: 0.4784020185470581\n","Time per epoch: 7.64970588684082 seconds\n","Epoch: 45; Training loss: 0.48722603917121887\n","Epoch: 45; Val loss: 0.49180641770362854\n","Time per epoch: 7.792457580566406 seconds\n","Epoch: 46; Training loss: 0.49111127853393555\n","Epoch: 46; Val loss: 0.4886949062347412\n","Time per epoch: 7.64829158782959 seconds\n","Epoch: 47; Training loss: 0.48596054315567017\n","Epoch: 47; Val loss: 0.5319896936416626\n","Time per epoch: 7.661365509033203 seconds\n","Epoch: 48; Training loss: 0.48524239659309387\n","Epoch: 48; Val loss: 0.6004306674003601\n","Time per epoch: 7.640590667724609 seconds\n","Epoch: 49; Training loss: 0.4778319299221039\n","Epoch: 49; Val loss: 0.4835231602191925\n","Time per epoch: 7.660876512527466 seconds\n","Epoch: 50; Training loss: 0.47277700901031494\n","Epoch: 50; Val loss: 0.574345052242279\n","Time per epoch: 7.829511880874634 seconds\n","Epoch: 51; Training loss: 0.4716412425041199\n","Epoch: 51; Val loss: 0.4952472746372223\n","Time per epoch: 7.655229568481445 seconds\n","Epoch: 52; Training loss: 0.46309584379196167\n","Epoch: 52; Val loss: 0.47329211235046387\n","Time per epoch: 7.722810506820679 seconds\n","Epoch: 53; Training loss: 0.4626973569393158\n","Epoch: 53; Val loss: 0.4624636471271515\n","Time per epoch: 7.667528390884399 seconds\n","Epoch: 54; Training loss: 0.4541258215904236\n","Epoch: 54; Val loss: 0.4618315100669861\n","Time per epoch: 7.840398550033569 seconds\n","Epoch: 55; Training loss: 0.455584317445755\n","Epoch: 55; Val loss: 0.47251272201538086\n","Time per epoch: 7.818283319473267 seconds\n","Epoch: 56; Training loss: 0.44902503490448\n","Epoch: 56; Val loss: 0.4813898205757141\n","Time per epoch: 7.64889931678772 seconds\n","Epoch: 57; Training loss: 0.4511072635650635\n","Epoch: 57; Val loss: 0.4839772880077362\n","Time per epoch: 7.666817903518677 seconds\n","Epoch: 58; Training loss: 0.4370345175266266\n","Epoch: 58; Val loss: 0.4670843780040741\n","Time per epoch: 7.650843381881714 seconds\n","Epoch: 59; Training loss: 0.4344603717327118\n","Epoch: 59; Val loss: 0.4452614188194275\n","Time per epoch: 7.666100263595581 seconds\n","Epoch: 60; Training loss: 0.4321694076061249\n","Epoch: 60; Val loss: 0.5000600814819336\n","Time per epoch: 7.828573942184448 seconds\n","Epoch: 61; Training loss: 0.42765989899635315\n","Epoch: 61; Val loss: 0.4811745882034302\n","Time per epoch: 7.835943937301636 seconds\n","Epoch: 62; Training loss: 0.43449631333351135\n","Epoch: 62; Val loss: 0.6049521565437317\n","Time per epoch: 7.64769434928894 seconds\n","Epoch: 63; Training loss: 0.43819916248321533\n","Epoch: 63; Val loss: 0.4598701000213623\n","Time per epoch: 7.662297248840332 seconds\n","Epoch: 64; Training loss: 0.43041470646858215\n","Epoch: 64; Val loss: 0.46326738595962524\n","Time per epoch: 7.650079727172852 seconds\n","Epoch: 65; Training loss: 0.4273596704006195\n","Epoch: 65; Val loss: 0.5026865005493164\n","Time per epoch: 7.6580970287323 seconds\n","Epoch: 66; Training loss: 0.42107611894607544\n","Epoch: 66; Val loss: 0.4565425217151642\n","Time per epoch: 7.650317192077637 seconds\n","Epoch: 67; Training loss: 0.42405831813812256\n","Epoch: 67; Val loss: 0.45161014795303345\n","Time per epoch: 7.8417041301727295 seconds\n","Epoch: 68; Training loss: 0.4145345985889435\n","Epoch: 68; Val loss: 0.4578138291835785\n","Time per epoch: 7.8036229610443115 seconds\n","Epoch: 69; Training loss: 0.41485023498535156\n","Epoch: 69; Val loss: 0.4555686414241791\n","Time per epoch: 7.662203311920166 seconds\n","Epoch: 70; Training loss: 0.4113750159740448\n","Epoch: 70; Val loss: 0.4686843454837799\n","Time per epoch: 7.650261878967285 seconds\n","Epoch: 71; Training loss: 0.4096747934818268\n","Epoch: 71; Val loss: 0.44881632924079895\n","Time per epoch: 7.661498785018921 seconds\n","Epoch: 72; Training loss: 0.41393983364105225\n","Epoch: 72; Val loss: 0.44717511534690857\n","Time per epoch: 7.821166038513184 seconds\n","Epoch: 73; Training loss: 0.4064592123031616\n","Epoch: 73; Val loss: 0.44325563311576843\n","Time per epoch: 7.664052724838257 seconds\n","Epoch: 74; Training loss: 0.4035577178001404\n","Epoch: 74; Val loss: 0.46855831146240234\n","Time per epoch: 7.7856597900390625 seconds\n","Epoch: 75; Training loss: 0.4015103280544281\n","Epoch: 75; Val loss: 0.5016170144081116\n","Time per epoch: 7.6610047817230225 seconds\n","Epoch: 76; Training loss: 0.4059387743473053\n","Epoch: 76; Val loss: 0.4595358669757843\n","Time per epoch: 7.650757789611816 seconds\n","Epoch: 77; Training loss: 0.3989839255809784\n","Epoch: 77; Val loss: 0.4529290795326233\n","Time per epoch: 7.663576126098633 seconds\n","Epoch: 78; Training loss: 0.39686480164527893\n","Epoch: 78; Val loss: 0.4794567823410034\n","Time per epoch: 7.808917999267578 seconds\n","Epoch: 79; Training loss: 0.4017714858055115\n","Epoch: 79; Val loss: 0.4574580490589142\n","Time per epoch: 7.662298202514648 seconds\n","Epoch: 80; Training loss: 0.40069490671157837\n","Epoch: 80; Val loss: 0.4534142315387726\n","Time per epoch: 7.687894344329834 seconds\n","Epoch: 81; Training loss: 0.41427528858184814\n","Epoch: 81; Val loss: 0.4391798675060272\n","Time per epoch: 7.664961576461792 seconds\n","Epoch: 82; Training loss: 0.3983118534088135\n","Epoch: 82; Val loss: 0.44921231269836426\n","Time per epoch: 7.653956890106201 seconds\n","Epoch: 83; Training loss: 0.3912210166454315\n","Epoch: 83; Val loss: 0.4529964327812195\n","Time per epoch: 7.66089129447937 seconds\n","Epoch: 84; Training loss: 0.38981080055236816\n","Epoch: 84; Val loss: 0.5038816928863525\n","Time per epoch: 7.836256980895996 seconds\n","Epoch: 85; Training loss: 0.3845885694026947\n","Epoch: 85; Val loss: 0.47554513812065125\n","Time per epoch: 7.8056721687316895 seconds\n","Epoch: 86; Training loss: 0.39156270027160645\n","Epoch: 86; Val loss: 0.4316937029361725\n","Time per epoch: 7.6490373611450195 seconds\n","Epoch: 87; Training loss: 0.3856845796108246\n","Epoch: 87; Val loss: 0.43356508016586304\n","Time per epoch: 7.6690239906311035 seconds\n","Epoch: 88; Training loss: 0.38178959488868713\n","Epoch: 88; Val loss: 0.46782946586608887\n","Time per epoch: 7.650569677352905 seconds\n","Epoch: 89; Training loss: 0.382548987865448\n","Epoch: 89; Val loss: 0.4382084012031555\n","Time per epoch: 7.842426300048828 seconds\n","Epoch: 90; Training loss: 0.3867429494857788\n","Epoch: 90; Val loss: 0.44418299198150635\n","Time per epoch: 7.801147699356079 seconds\n","Epoch: 91; Training loss: 0.3824663758277893\n","Epoch: 91; Val loss: 0.44035860896110535\n","Time per epoch: 7.660546064376831 seconds\n","Epoch: 92; Training loss: 0.3802335560321808\n","Epoch: 92; Val loss: 0.45543086528778076\n","Time per epoch: 7.649393081665039 seconds\n","Epoch: 93; Training loss: 0.38232409954071045\n","Epoch: 93; Val loss: 0.466356486082077\n","Time per epoch: 7.662555694580078 seconds\n","Epoch: 94; Training loss: 0.380613774061203\n","Epoch: 94; Val loss: 0.4609301686286926\n","Time per epoch: 7.648900032043457 seconds\n","Epoch: 95; Training loss: 0.36788350343704224\n","Epoch: 95; Val loss: 0.43445008993148804\n","Time per epoch: 7.857571601867676 seconds\n","Epoch: 96; Training loss: 0.3798576295375824\n","Epoch: 96; Val loss: 0.4606810212135315\n","Time per epoch: 7.647324323654175 seconds\n","Epoch: 97; Training loss: 0.374185711145401\n","Epoch: 97; Val loss: 0.46639060974121094\n","Time per epoch: 7.8366265296936035 seconds\n","Epoch: 98; Training loss: 0.37589722871780396\n","Epoch: 98; Val loss: 0.44013169407844543\n","Time per epoch: 7.649956464767456 seconds\n","Epoch: 99; Training loss: 0.3762025535106659\n","Epoch: 99; Val loss: 0.43689674139022827\n","Time per epoch: 7.662396192550659 seconds\n","Epoch: 100; Training loss: 0.3774246573448181\n","Epoch: 100; Val loss: 0.4253331422805786\n","Time per epoch: 7.6517767906188965 seconds\n","Epoch: 101; Training loss: 0.3748170733451843\n","Epoch: 101; Val loss: 0.4291054308414459\n","Time per epoch: 7.660353183746338 seconds\n","Epoch: 102; Training loss: 0.37215638160705566\n","Epoch: 102; Val loss: 0.4414675235748291\n","Time per epoch: 7.8337318897247314 seconds\n","Epoch: 103; Training loss: 0.3737778067588806\n","Epoch: 103; Val loss: 0.441104531288147\n","Time per epoch: 7.663320064544678 seconds\n","Epoch: 104; Training loss: 0.3689132034778595\n","Epoch: 104; Val loss: 0.4523202180862427\n","Time per epoch: 7.783721446990967 seconds\n","Epoch: 105; Training loss: 0.36719927191734314\n","Epoch: 105; Val loss: 0.41985100507736206\n","Time per epoch: 7.66243314743042 seconds\n","Epoch: 106; Training loss: 0.35838088393211365\n","Epoch: 106; Val loss: 0.4709078073501587\n","Time per epoch: 7.648462772369385 seconds\n","Epoch: 107; Training loss: 0.3662334382534027\n","Epoch: 107; Val loss: 0.43891286849975586\n","Time per epoch: 7.842196464538574 seconds\n","Epoch: 108; Training loss: 0.3670293688774109\n","Epoch: 108; Val loss: 0.4529692232608795\n","Time per epoch: 7.65040135383606 seconds\n","Epoch: 109; Training loss: 0.36111894249916077\n","Epoch: 109; Val loss: 0.4384729564189911\n","Time per epoch: 7.740905284881592 seconds\n","Epoch: 110; Training loss: 0.3601471185684204\n","Epoch: 110; Val loss: 0.4385630190372467\n","Time per epoch: 7.6508471965789795 seconds\n","Epoch: 111; Training loss: 0.35762691497802734\n","Epoch: 111; Val loss: 0.4505813419818878\n","Time per epoch: 7.6644837856292725 seconds\n","Epoch: 112; Training loss: 0.3586368262767792\n","Epoch: 112; Val loss: 0.43220704793930054\n","Time per epoch: 7.857398986816406 seconds\n","Epoch: 113; Training loss: 0.35870206356048584\n","Epoch: 113; Val loss: 0.43690332770347595\n","Time per epoch: 7.822857141494751 seconds\n","Epoch: 114; Training loss: 0.3445795774459839\n","Epoch: 114; Val loss: 0.46618539094924927\n","Time per epoch: 7.64754581451416 seconds\n","Epoch: 115; Training loss: 0.36010777950286865\n","Epoch: 115; Val loss: 0.45242881774902344\n","Time per epoch: 7.662416219711304 seconds\n","Epoch: 116; Training loss: 0.3549982011318207\n","Epoch: 116; Val loss: 0.4391207993030548\n","Time per epoch: 7.649816513061523 seconds\n","Epoch: 117; Training loss: 0.34496545791625977\n","Epoch: 117; Val loss: 0.43392398953437805\n","Time per epoch: 7.662383556365967 seconds\n","Epoch: 118; Training loss: 0.3580451011657715\n","Epoch: 118; Val loss: 0.45381829142570496\n","Time per epoch: 7.649044752120972 seconds\n","Epoch: 119; Training loss: 0.3413030207157135\n","Epoch: 119; Val loss: 0.4875318109989166\n","Time per epoch: 7.850908994674683 seconds\n","Epoch: 120; Training loss: 0.3436829447746277\n","Epoch: 120; Val loss: 0.45137980580329895\n","Time per epoch: 7.813980340957642 seconds\n","Epoch: 121; Training loss: 0.3457584083080292\n","Epoch: 121; Val loss: 0.43694546818733215\n","Time per epoch: 7.662282705307007 seconds\n","Epoch: 122; Training loss: 0.3448229432106018\n","Epoch: 122; Val loss: 0.43855586647987366\n","Time per epoch: 7.648753643035889 seconds\n","Epoch: 123; Training loss: 0.3417568802833557\n","Epoch: 123; Val loss: 0.4345618784427643\n","Time per epoch: 7.663088321685791 seconds\n","Epoch: 124; Training loss: 0.3418716490268707\n","Epoch: 124; Val loss: 0.43903008103370667\n","Time per epoch: 7.842135667800903 seconds\n","Epoch: 125; Training loss: 0.34319472312927246\n","Epoch: 125; Val loss: 0.46489423513412476\n","Time per epoch: 7.807741403579712 seconds\n","Epoch: 126; Training loss: 0.33905187249183655\n","Epoch: 126; Val loss: 0.4652303159236908\n","Time per epoch: 7.648879766464233 seconds\n","Epoch: 127; Training loss: 0.3386864960193634\n","Epoch: 127; Val loss: 0.45298340916633606\n","Time per epoch: 7.662144422531128 seconds\n","Epoch: 128; Training loss: 0.3371311128139496\n","Epoch: 128; Val loss: 0.4552668333053589\n","Time per epoch: 7.646501302719116 seconds\n","Epoch: 129; Training loss: 0.34005922079086304\n","Epoch: 129; Val loss: 0.43064042925834656\n","Time per epoch: 7.663304090499878 seconds\n","Epoch: 130; Training loss: 0.336448609828949\n","Epoch: 130; Val loss: 0.45231518149375916\n","Time per epoch: 7.824435710906982 seconds\n","Epoch: 131; Training loss: 0.33640632033348083\n","Epoch: 131; Val loss: 0.43943238258361816\n","Time per epoch: 7.661532640457153 seconds\n","Epoch: 132; Training loss: 0.3283006250858307\n","Epoch: 132; Val loss: 0.4335261583328247\n","Time per epoch: 7.742009878158569 seconds\n","Epoch: 133; Training loss: 0.3245869576931\n","Epoch: 133; Val loss: 0.45978978276252747\n","Time per epoch: 7.663090467453003 seconds\n","Epoch: 134; Training loss: 0.3261885941028595\n","Epoch: 134; Val loss: 0.44347453117370605\n","Time per epoch: 7.650496006011963 seconds\n","Epoch: 135; Training loss: 0.32984063029289246\n","Epoch: 135; Val loss: 0.45535287261009216\n","Time per epoch: 7.6614460945129395 seconds\n","Epoch: 136; Training loss: 0.33097249269485474\n","Epoch: 136; Val loss: 0.4367077946662903\n","Time per epoch: 7.648175954818726 seconds\n","Epoch: 137; Training loss: 0.3252699077129364\n","Epoch: 137; Val loss: 0.42995309829711914\n","Time per epoch: 7.840629816055298 seconds\n","Epoch: 138; Training loss: 0.31883981823921204\n","Epoch: 138; Val loss: 0.4209725558757782\n","Time per epoch: 7.6476194858551025 seconds\n","Epoch: 139; Training loss: 0.3352029025554657\n","Epoch: 139; Val loss: 0.4279879629611969\n","Time per epoch: 7.699734210968018 seconds\n","Epoch: 140; Training loss: 0.32098668813705444\n","Epoch: 140; Val loss: 0.44123026728630066\n","Time per epoch: 7.650003433227539 seconds\n","Epoch: 141; Training loss: 0.3236226737499237\n","Epoch: 141; Val loss: 0.44583794474601746\n","Time per epoch: 7.860622406005859 seconds\n","Epoch: 142; Training loss: 0.32152339816093445\n","Epoch: 142; Val loss: 0.4249894917011261\n","Time per epoch: 7.827214241027832 seconds\n","Epoch: 143; Training loss: 0.31085070967674255\n","Epoch: 143; Val loss: 0.4443202316761017\n","Time per epoch: 7.666642427444458 seconds\n","Epoch: 144; Training loss: 0.3141478896141052\n","Epoch: 144; Val loss: 0.4367583394050598\n","Time per epoch: 7.64995813369751 seconds\n","Epoch: 145; Training loss: 0.31615155935287476\n","Epoch: 145; Val loss: 0.4494338035583496\n","Time per epoch: 7.65905499458313 seconds\n","Epoch: 146; Training loss: 0.31809282302856445\n","Epoch: 146; Val loss: 0.41594576835632324\n","Time per epoch: 7.64895224571228 seconds\n","Epoch: 147; Training loss: 0.3141695559024811\n","Epoch: 147; Val loss: 0.4275166988372803\n","Time per epoch: 7.852465391159058 seconds\n","Epoch: 148; Training loss: 0.3107532262802124\n","Epoch: 148; Val loss: 0.4348127245903015\n","Time per epoch: 7.795106887817383 seconds\n","Epoch: 149; Training loss: 0.30825474858283997\n","Epoch: 149; Val loss: 0.422157347202301\n","Time per epoch: 7.661331653594971 seconds\n","Epoch: 150; Training loss: 0.31522488594055176\n","Epoch: 150; Val loss: 0.4193743169307709\n","Time per epoch: 7.650876045227051 seconds\n","Epoch: 151; Training loss: 0.31366458535194397\n","Epoch: 151; Val loss: 0.42733803391456604\n","Time per epoch: 7.662751913070679 seconds\n","Epoch: 152; Training loss: 0.30691203474998474\n","Epoch: 152; Val loss: 0.4453904628753662\n","Time per epoch: 7.6490936279296875 seconds\n","Epoch: 153; Training loss: 0.31525295972824097\n","Epoch: 153; Val loss: 0.4878775179386139\n","Time per epoch: 7.650062084197998 seconds\n","Epoch: 154; Training loss: 0.322551965713501\n","Epoch: 154; Val loss: 0.4233096241950989\n","Time per epoch: 7.831287622451782 seconds\n","Epoch: 155; Training loss: 0.30645397305488586\n","Epoch: 155; Val loss: 0.4319974482059479\n","Time per epoch: 7.663041114807129 seconds\n","Epoch: 156; Training loss: 0.3029506206512451\n","Epoch: 156; Val loss: 0.43284183740615845\n","Time per epoch: 7.847931385040283 seconds\n","Epoch: 157; Training loss: 0.31229716539382935\n","Epoch: 157; Val loss: 0.4247440993785858\n","Time per epoch: 7.661504745483398 seconds\n","Epoch: 158; Training loss: 0.2971876561641693\n","Epoch: 158; Val loss: 0.477311909198761\n","Time per epoch: 7.647008180618286 seconds\n","Epoch: 159; Training loss: 0.30703940987586975\n","Epoch: 159; Val loss: 0.46582046151161194\n","Time per epoch: 7.834075450897217 seconds\n","Epoch: 160; Training loss: 0.2997336685657501\n","Epoch: 160; Val loss: 0.4740101099014282\n","Time per epoch: 7.649331331253052 seconds\n","Epoch: 161; Training loss: 0.30537328124046326\n","Epoch: 161; Val loss: 0.44334375858306885\n","Time per epoch: 7.770150899887085 seconds\n","Epoch: 162; Training loss: 0.30485105514526367\n","Epoch: 162; Val loss: 0.4365862309932709\n","Time per epoch: 7.648524522781372 seconds\n","Epoch: 163; Training loss: 0.2936168611049652\n","Epoch: 163; Val loss: 0.4685699939727783\n","Time per epoch: 7.665723562240601 seconds\n","Epoch: 164; Training loss: 0.29571235179901123\n","Epoch: 164; Val loss: 0.411607950925827\n","Time per epoch: 7.841468334197998 seconds\n","Epoch: 165; Training loss: 0.3000061511993408\n","Epoch: 165; Val loss: 0.4289005994796753\n","Time per epoch: 7.819567441940308 seconds\n","Epoch: 166; Training loss: 0.2994850277900696\n","Epoch: 166; Val loss: 0.43860575556755066\n","Time per epoch: 7.646239995956421 seconds\n","Epoch: 167; Training loss: 0.30156606435775757\n","Epoch: 167; Val loss: 0.41030511260032654\n","Time per epoch: 7.664187908172607 seconds\n","Epoch: 168; Training loss: 0.2933436632156372\n","Epoch: 168; Val loss: 0.4146614670753479\n","Time per epoch: 7.651727199554443 seconds\n","Epoch: 169; Training loss: 0.3012324571609497\n","Epoch: 169; Val loss: 0.4239552319049835\n","Time per epoch: 7.66179633140564 seconds\n","Epoch: 170; Training loss: 0.2975934147834778\n","Epoch: 170; Val loss: 0.41798263788223267\n","Time per epoch: 7.6493752002716064 seconds\n","Epoch: 171; Training loss: 0.294658899307251\n","Epoch: 171; Val loss: 0.41487088799476624\n","Time per epoch: 7.864258289337158 seconds\n","Epoch: 172; Training loss: 0.2886880040168762\n","Epoch: 172; Val loss: 0.4399537444114685\n","Time per epoch: 7.805288553237915 seconds\n","Epoch: 173; Training loss: 0.3006993234157562\n","Epoch: 173; Val loss: 0.42030972242355347\n","Time per epoch: 7.660256862640381 seconds\n","Epoch: 174; Training loss: 0.2902963161468506\n","Epoch: 174; Val loss: 0.4219543933868408\n","Time per epoch: 7.649457931518555 seconds\n","Epoch: 175; Training loss: 0.29396146535873413\n","Epoch: 175; Val loss: 0.43578439950942993\n","Time per epoch: 7.6637773513793945 seconds\n","Epoch: 176; Training loss: 0.30015358328819275\n","Epoch: 176; Val loss: 0.4309692680835724\n","Time per epoch: 7.847867727279663 seconds\n","Epoch: 177; Training loss: 0.2887076437473297\n","Epoch: 177; Val loss: 0.40609195828437805\n","Time per epoch: 7.818267107009888 seconds\n","Epoch: 178; Training loss: 0.29071831703186035\n","Epoch: 178; Val loss: 0.41321098804473877\n","Time per epoch: 7.647777318954468 seconds\n","Epoch: 179; Training loss: 0.2834177315235138\n","Epoch: 179; Val loss: 0.41587400436401367\n","Time per epoch: 7.665622711181641 seconds\n","Epoch: 180; Training loss: 0.28732872009277344\n","Epoch: 180; Val loss: 0.4246298670768738\n","Time per epoch: 7.65010929107666 seconds\n","Epoch: 181; Training loss: 0.2851645052433014\n","Epoch: 181; Val loss: 0.42612260580062866\n","Time per epoch: 7.660883903503418 seconds\n","Epoch: 182; Training loss: 0.291820764541626\n","Epoch: 182; Val loss: 0.42737406492233276\n","Time per epoch: 7.82449197769165 seconds\n","Epoch: 183; Training loss: 0.2808908224105835\n","Epoch: 183; Val loss: 0.433309942483902\n","Time per epoch: 7.660152435302734 seconds\n","Epoch: 184; Training loss: 0.2892773151397705\n","Epoch: 184; Val loss: 0.43583250045776367\n","Time per epoch: 7.790379762649536 seconds\n","Epoch: 185; Training loss: 0.287548303604126\n","Epoch: 185; Val loss: 0.413698673248291\n","Time per epoch: 7.661478042602539 seconds\n","Epoch: 186; Training loss: 0.2813001871109009\n","Epoch: 186; Val loss: 0.4032340943813324\n","Time per epoch: 7.650682687759399 seconds\n","Epoch: 187; Training loss: 0.28419429063796997\n","Epoch: 187; Val loss: 0.44311270117759705\n","Time per epoch: 7.6650550365448 seconds\n","Epoch: 188; Training loss: 0.2809545695781708\n","Epoch: 188; Val loss: 0.4280987083911896\n","Time per epoch: 7.6418352127075195 seconds\n","Epoch: 189; Training loss: 0.2823864817619324\n","Epoch: 189; Val loss: 0.4363916516304016\n","Time per epoch: 7.850642442703247 seconds\n","Epoch: 190; Training loss: 0.2823595106601715\n","Epoch: 190; Val loss: 0.40163499116897583\n","Time per epoch: 7.649136781692505 seconds\n","Epoch: 191; Training loss: 0.28184473514556885\n","Epoch: 191; Val loss: 0.4221744239330292\n","Time per epoch: 7.756329298019409 seconds\n","Epoch: 192; Training loss: 0.2760816514492035\n","Epoch: 192; Val loss: 0.4155505895614624\n","Time per epoch: 7.650494337081909 seconds\n","Epoch: 193; Training loss: 0.28353551030158997\n","Epoch: 193; Val loss: 0.4514433443546295\n","Time per epoch: 7.659449338912964 seconds\n","Epoch: 194; Training loss: 0.27966687083244324\n","Epoch: 194; Val loss: 0.4285326898097992\n","Time per epoch: 7.821168422698975 seconds\n","Epoch: 195; Training loss: 0.2803879678249359\n","Epoch: 195; Val loss: 0.536851704120636\n","Time per epoch: 7.661404848098755 seconds\n","Epoch: 196; Training loss: 0.29066798090934753\n","Epoch: 196; Val loss: 0.4246353209018707\n","Time per epoch: 7.663558006286621 seconds\n","Epoch: 197; Training loss: 0.27887067198753357\n","Epoch: 197; Val loss: 0.43596869707107544\n","Time per epoch: 7.666165113449097 seconds\n","Epoch: 198; Training loss: 0.27172690629959106\n","Epoch: 198; Val loss: 0.40796005725860596\n","Time per epoch: 7.650063753128052 seconds\n","Epoch: 199; Training loss: 0.2749229669570923\n","Epoch: 199; Val loss: 0.41847583651542664\n","Time per epoch: 7.848350286483765 seconds\n","Epoch: 200; Training loss: 0.28481364250183105\n","Epoch: 200; Val loss: 0.4365244507789612\n","Time per epoch: 7.816154956817627 seconds\n","Epoch: 201; Training loss: 0.2859877645969391\n","Epoch: 201; Val loss: 0.42902684211730957\n","Time per epoch: 7.661290645599365 seconds\n","Epoch: 202; Training loss: 0.28483128547668457\n","Epoch: 202; Val loss: 0.439075767993927\n","Time per epoch: 7.650924205780029 seconds\n","Epoch: 203; Training loss: 0.2744913697242737\n","Epoch: 203; Val loss: 0.432635635137558\n","Time per epoch: 7.661538600921631 seconds\n","Epoch: 204; Training loss: 0.28461477160453796\n","Epoch: 204; Val loss: 0.4361448585987091\n","Time per epoch: 7.649370193481445 seconds\n","Epoch: 205; Training loss: 0.28698158264160156\n","Epoch: 205; Val loss: 0.42922139167785645\n","Time per epoch: 7.663604974746704 seconds\n","Epoch: 206; Training loss: 0.27585819363594055\n","Epoch: 206; Val loss: 0.40161824226379395\n","Time per epoch: 7.8372673988342285 seconds\n","Epoch: 207; Training loss: 0.28117835521698\n","Epoch: 207; Val loss: 0.43153509497642517\n","Time per epoch: 7.805671215057373 seconds\n","Epoch: 208; Training loss: 0.27914366126060486\n","Epoch: 208; Val loss: 0.4098159968852997\n","Time per epoch: 7.647894382476807 seconds\n","Epoch: 209; Training loss: 0.2701243460178375\n","Epoch: 209; Val loss: 0.42922425270080566\n","Time per epoch: 7.662069082260132 seconds\n","Epoch: 210; Training loss: 0.2729056179523468\n","Epoch: 210; Val loss: 0.4445497691631317\n","Time per epoch: 7.648139238357544 seconds\n","Epoch: 211; Training loss: 0.2725335955619812\n","Epoch: 211; Val loss: 0.42300695180892944\n","Time per epoch: 7.838189125061035 seconds\n","Epoch: 212; Training loss: 0.27069222927093506\n","Epoch: 212; Val loss: 0.4197063744068146\n","Time per epoch: 7.648857593536377 seconds\n","Epoch: 213; Training loss: 0.2819148898124695\n","Epoch: 213; Val loss: 0.45669111609458923\n","Time per epoch: 7.822616338729858 seconds\n","Epoch: 214; Training loss: 0.28955408930778503\n","Epoch: 214; Val loss: 0.46689796447753906\n","Time per epoch: 7.650022268295288 seconds\n","Epoch: 215; Training loss: 0.2776777446269989\n","Epoch: 215; Val loss: 0.4090544283390045\n","Time per epoch: 7.662004470825195 seconds\n","Epoch: 216; Training loss: 0.27582940459251404\n","Epoch: 216; Val loss: 0.4415764808654785\n","Time per epoch: 7.649453401565552 seconds\n","Epoch: 217; Training loss: 0.27380529046058655\n","Epoch: 217; Val loss: 0.41459041833877563\n","Time per epoch: 7.848686933517456 seconds\n","Epoch: 218; Training loss: 0.28564542531967163\n","Epoch: 218; Val loss: 0.44483521580696106\n","Time per epoch: 7.652939796447754 seconds\n","Epoch: 219; Training loss: 0.26662445068359375\n","Epoch: 219; Val loss: 0.42519524693489075\n","Time per epoch: 7.732585906982422 seconds\n","Epoch: 220; Training loss: 0.26846280694007874\n","Epoch: 220; Val loss: 0.41492167115211487\n","Time per epoch: 7.650005102157593 seconds\n","Epoch: 221; Training loss: 0.26777440309524536\n","Epoch: 221; Val loss: 0.41585737466812134\n","Time per epoch: 7.664846658706665 seconds\n","Epoch: 222; Training loss: 0.2686893939971924\n","Epoch: 222; Val loss: 0.41468334197998047\n","Time per epoch: 7.649251461029053 seconds\n","Epoch: 223; Training loss: 0.28062766790390015\n","Epoch: 223; Val loss: 0.4195806086063385\n","Time per epoch: 7.856931447982788 seconds\n","Epoch: 224; Training loss: 0.2699296772480011\n","Epoch: 224; Val loss: 0.4383702576160431\n","Time per epoch: 7.810967206954956 seconds\n","Epoch: 225; Training loss: 0.2704952359199524\n","Epoch: 225; Val loss: 0.42102861404418945\n","Time per epoch: 7.661315679550171 seconds\n","Epoch: 226; Training loss: 0.27055978775024414\n","Epoch: 226; Val loss: 0.43309757113456726\n","Time per epoch: 7.651917219161987 seconds\n","Epoch: 227; Training loss: 0.27721619606018066\n","Epoch: 227; Val loss: 0.4374261498451233\n","Time per epoch: 7.663857698440552 seconds\n","Epoch: 228; Training loss: 0.27175894379615784\n","Epoch: 228; Val loss: 0.41145360469818115\n","Time per epoch: 7.847653865814209 seconds\n","Epoch: 229; Training loss: 0.27035245299339294\n","Epoch: 229; Val loss: 0.40698593854904175\n","Time per epoch: 7.831769943237305 seconds\n","Epoch: 230; Training loss: 0.27285367250442505\n","Epoch: 230; Val loss: 0.4441814124584198\n","Time per epoch: 7.647623062133789 seconds\n","Epoch: 231; Training loss: 0.26480939984321594\n","Epoch: 231; Val loss: 0.4152040183544159\n","Time per epoch: 7.663126230239868 seconds\n","Epoch: 232; Training loss: 0.2659474015235901\n","Epoch: 232; Val loss: 0.41212040185928345\n","Time per epoch: 7.651668071746826 seconds\n","Epoch: 233; Training loss: 0.2657454013824463\n","Epoch: 233; Val loss: 0.44175803661346436\n","Time per epoch: 7.663476467132568 seconds\n","Epoch: 234; Training loss: 0.27102193236351013\n","Epoch: 234; Val loss: 0.41543328762054443\n","Time per epoch: 7.83887791633606 seconds\n","Epoch: 235; Training loss: 0.26392415165901184\n","Epoch: 235; Val loss: 0.41708892583847046\n","Time per epoch: 7.798794984817505 seconds\n","Epoch: 236; Training loss: 0.26519736647605896\n","Epoch: 236; Val loss: 0.4336187243461609\n","Time per epoch: 7.647835731506348 seconds\n","Epoch: 237; Training loss: 0.2717854380607605\n","Epoch: 237; Val loss: 0.40895530581474304\n","Time per epoch: 7.663201332092285 seconds\n","Epoch: 238; Training loss: 0.2650516629219055\n","Epoch: 238; Val loss: 0.42658835649490356\n","Time per epoch: 7.649255752563477 seconds\n","Epoch: 239; Training loss: 0.2685355544090271\n","Epoch: 239; Val loss: 0.4043663740158081\n","Time per epoch: 7.66219687461853 seconds\n","Epoch: 240; Training loss: 0.2656235992908478\n","Epoch: 240; Val loss: 0.44515296816825867\n","Time per epoch: 7.648499250411987 seconds\n","Epoch: 241; Training loss: 0.2612074613571167\n","Epoch: 241; Val loss: 0.4012192189693451\n","Time per epoch: 7.843792200088501 seconds\n","Epoch: 242; Training loss: 0.26913121342658997\n","Epoch: 242; Val loss: 0.418680340051651\n","Time per epoch: 7.643506288528442 seconds\n","Epoch: 243; Training loss: 0.2669842541217804\n","Epoch: 243; Val loss: 0.41986891627311707\n","Time per epoch: 7.809879302978516 seconds\n","Epoch: 244; Training loss: 0.26235243678092957\n","Epoch: 244; Val loss: 0.4022124409675598\n","Time per epoch: 7.648994445800781 seconds\n","Epoch: 245; Training loss: 0.2602004408836365\n","Epoch: 245; Val loss: 0.41250237822532654\n","Time per epoch: 7.660925388336182 seconds\n","Epoch: 246; Training loss: 0.2671360969543457\n","Epoch: 246; Val loss: 0.43842872977256775\n","Time per epoch: 7.822509765625 seconds\n","Epoch: 247; Training loss: 0.2684117257595062\n","Epoch: 247; Val loss: 0.4044622778892517\n","Time per epoch: 7.66246485710144 seconds\n","Epoch: 248; Training loss: 0.2579469084739685\n","Epoch: 248; Val loss: 0.4194120764732361\n","Time per epoch: 7.749090671539307 seconds\n","Epoch: 249; Training loss: 0.26206791400909424\n","Epoch: 249; Val loss: 0.45397770404815674\n","Time per epoch: 7.661484718322754 seconds\n","Epoch: 250; Training loss: 0.26431408524513245\n","Epoch: 250; Val loss: 0.4295770525932312\n","Time per epoch: 7.649943590164185 seconds\n","Epoch: 251; Training loss: 0.26954394578933716\n","Epoch: 251; Val loss: 0.3949948251247406\n","Time per epoch: 7.85117506980896 seconds\n","Epoch: 252; Training loss: 0.2652404308319092\n","Epoch: 252; Val loss: 0.40682435035705566\n","Time per epoch: 7.821237325668335 seconds\n","Epoch: 253; Training loss: 0.25491660833358765\n","Epoch: 253; Val loss: 0.4095880687236786\n","Time per epoch: 7.662142992019653 seconds\n","Epoch: 254; Training loss: 0.2622554898262024\n","Epoch: 254; Val loss: 0.40937337279319763\n","Time per epoch: 7.651007890701294 seconds\n","Epoch: 255; Training loss: 0.2694247364997864\n","Epoch: 255; Val loss: 0.42814135551452637\n","Time per epoch: 7.663248538970947 seconds\n","Epoch: 256; Training loss: 0.2665615975856781\n","Epoch: 256; Val loss: 0.4309089183807373\n","Time per epoch: 7.649576425552368 seconds\n","Epoch: 257; Training loss: 0.2602054476737976\n","Epoch: 257; Val loss: 0.4174562394618988\n","Time per epoch: 7.662550210952759 seconds\n","Epoch: 258; Training loss: 0.26534727215766907\n","Epoch: 258; Val loss: 0.4392097592353821\n","Time per epoch: 7.833827972412109 seconds\n","Epoch: 259; Training loss: 0.26522648334503174\n","Epoch: 259; Val loss: 0.3927151560783386\n","Time per epoch: 7.814794301986694 seconds\n","Epoch: 260; Training loss: 0.2658814787864685\n","Epoch: 260; Val loss: 0.4214872717857361\n","Time per epoch: 7.6519715785980225 seconds\n","Epoch: 261; Training loss: 0.2654295861721039\n","Epoch: 261; Val loss: 0.42817404866218567\n","Time per epoch: 7.652237415313721 seconds\n","Epoch: 262; Training loss: 0.25487008690834045\n","Epoch: 262; Val loss: 0.4742301106452942\n","Time per epoch: 7.648840665817261 seconds\n","Epoch: 263; Training loss: 0.2630341649055481\n","Epoch: 263; Val loss: 0.39941802620887756\n","Time per epoch: 7.8513898849487305 seconds\n","Epoch: 264; Training loss: 0.2570062577724457\n","Epoch: 264; Val loss: 0.43025854229927063\n","Time per epoch: 7.793584108352661 seconds\n","Epoch: 265; Training loss: 0.25835004448890686\n","Epoch: 265; Val loss: 0.4336649477481842\n","Time per epoch: 7.67053747177124 seconds\n","Epoch: 266; Training loss: 0.25126320123672485\n","Epoch: 266; Val loss: 0.4230424761772156\n","Time per epoch: 7.651803016662598 seconds\n","Epoch: 267; Training loss: 0.2595893144607544\n","Epoch: 267; Val loss: 0.41935616731643677\n","Time per epoch: 7.666654109954834 seconds\n","Epoch: 268; Training loss: 0.27071473002433777\n","Epoch: 268; Val loss: 0.4054092466831207\n","Time per epoch: 7.6531760692596436 seconds\n","Epoch: 269; Training loss: 0.26175379753112793\n","Epoch: 269; Val loss: 0.4181789755821228\n","Time per epoch: 7.844350099563599 seconds\n","Epoch: 270; Training loss: 0.2664639353752136\n","Epoch: 270; Val loss: 0.40543925762176514\n","Time per epoch: 7.647837400436401 seconds\n","Epoch: 271; Training loss: 0.26535406708717346\n","Epoch: 271; Val loss: 0.39968252182006836\n","Time per epoch: 7.7828545570373535 seconds\n","Epoch: 272; Training loss: 0.26036742329597473\n","Epoch: 272; Val loss: 0.3943406939506531\n","Time per epoch: 7.650871276855469 seconds\n","Epoch: 273; Training loss: 0.25270217657089233\n","Epoch: 273; Val loss: 0.4378383457660675\n","Time per epoch: 7.675673961639404 seconds\n","Epoch: 274; Training loss: 0.259280800819397\n","Epoch: 274; Val loss: 0.4138316810131073\n","Time per epoch: 7.650928258895874 seconds\n","Epoch: 275; Training loss: 0.2571481764316559\n","Epoch: 275; Val loss: 0.40567412972450256\n","Time per epoch: 7.671259641647339 seconds\n","Epoch: 276; Training loss: 0.25954389572143555\n","Epoch: 276; Val loss: 0.42514023184776306\n","Time per epoch: 7.824213743209839 seconds\n","Epoch: 277; Training loss: 0.2563457190990448\n","Epoch: 277; Val loss: 0.416472464799881\n","Time per epoch: 7.671864748001099 seconds\n","Epoch: 278; Training loss: 0.25838249921798706\n","Epoch: 278; Val loss: 0.4211193323135376\n","Time per epoch: 7.706323146820068 seconds\n","Epoch: 279; Training loss: 0.25991541147232056\n","Epoch: 279; Val loss: 0.42285415530204773\n","Time per epoch: 7.6737072467803955 seconds\n","Epoch: 280; Training loss: 0.26122012734413147\n","Epoch: 280; Val loss: 0.41386690735816956\n","Time per epoch: 7.842839479446411 seconds\n","Epoch: 281; Training loss: 0.25590404868125916\n","Epoch: 281; Val loss: 0.4130244851112366\n","Time per epoch: 7.86815619468689 seconds\n","Epoch: 282; Training loss: 0.25416383147239685\n","Epoch: 282; Val loss: 0.4164387285709381\n","Time per epoch: 7.6470184326171875 seconds\n","Epoch: 283; Training loss: 0.26190099120140076\n","Epoch: 283; Val loss: 0.42573991417884827\n","Time per epoch: 7.671929359436035 seconds\n","Epoch: 284; Training loss: 0.25530335307121277\n","Epoch: 284; Val loss: 0.41912955045700073\n","Time per epoch: 7.649538278579712 seconds\n","Epoch: 285; Training loss: 0.2577003538608551\n","Epoch: 285; Val loss: 0.41427087783813477\n","Time per epoch: 7.675274133682251 seconds\n","Epoch: 286; Training loss: 0.26232224702835083\n","Epoch: 286; Val loss: 0.4259754419326782\n","Time per epoch: 7.838841199874878 seconds\n","Epoch: 287; Training loss: 0.2578471302986145\n","Epoch: 287; Val loss: 0.4067556858062744\n","Time per epoch: 7.8180601596832275 seconds\n","Epoch: 288; Training loss: 0.26262784004211426\n","Epoch: 288; Val loss: 0.40475156903266907\n","Time per epoch: 7.648199081420898 seconds\n","Epoch: 289; Training loss: 0.2569173276424408\n","Epoch: 289; Val loss: 0.4058295786380768\n","Time per epoch: 7.6726601123809814 seconds\n","Epoch: 290; Training loss: 0.24749229848384857\n","Epoch: 290; Val loss: 0.45270994305610657\n","Time per epoch: 7.649820566177368 seconds\n","Epoch: 291; Training loss: 0.26125508546829224\n","Epoch: 291; Val loss: 0.4163430631160736\n","Time per epoch: 7.674040794372559 seconds\n","Epoch: 292; Training loss: 0.2574758529663086\n","Epoch: 292; Val loss: 0.4642438292503357\n","Time per epoch: 7.649953603744507 seconds\n","Epoch: 293; Training loss: 0.26130297780036926\n","Epoch: 293; Val loss: 0.42209070920944214\n","Time per epoch: 7.850970029830933 seconds\n","Epoch: 294; Training loss: 0.25661295652389526\n","Epoch: 294; Val loss: 0.41288459300994873\n","Time per epoch: 7.82917857170105 seconds\n","Epoch: 295; Training loss: 0.2553211748600006\n","Epoch: 295; Val loss: 0.4151538014411926\n","Time per epoch: 7.674086809158325 seconds\n","Epoch: 296; Training loss: 0.2546370327472687\n","Epoch: 296; Val loss: 0.4232962131500244\n","Time per epoch: 7.644866704940796 seconds\n","Epoch: 297; Training loss: 0.24632664024829865\n","Epoch: 297; Val loss: 0.41837263107299805\n","Time per epoch: 7.671120882034302 seconds\n","Epoch: 298; Training loss: 0.25118666887283325\n","Epoch: 298; Val loss: 0.4254014194011688\n","Time per epoch: 7.827982425689697 seconds\n","Epoch: 299; Training loss: 0.24812519550323486\n","Epoch: 299; Val loss: 0.4300381541252136\n","Time per epoch: 7.669836759567261 seconds\n","Epoch: 300; Training loss: 0.2517614960670471\n","Epoch: 300; Val loss: 0.4256667494773865\n","Time per epoch: 7.773671627044678 seconds\n","Epoch: 301; Training loss: 0.24772284924983978\n","Epoch: 301; Val loss: 0.43811890482902527\n","Time per epoch: 7.673346757888794 seconds\n","Epoch: 302; Training loss: 0.24401724338531494\n","Epoch: 302; Val loss: 0.4101206064224243\n","Time per epoch: 7.650925636291504 seconds\n","Epoch: 303; Training loss: 0.25675874948501587\n","Epoch: 303; Val loss: 0.43350717425346375\n","Time per epoch: 7.672688722610474 seconds\n","Epoch: 304; Training loss: 0.2561683654785156\n","Epoch: 304; Val loss: 0.4287104606628418\n","Time per epoch: 7.815685749053955 seconds\n","Epoch: 305; Training loss: 0.25485947728157043\n","Epoch: 305; Val loss: 0.4099524915218353\n","Time per epoch: 7.671439170837402 seconds\n","Epoch: 306; Training loss: 0.2521458566188812\n","Epoch: 306; Val loss: 0.41870173811912537\n","Time per epoch: 7.660833835601807 seconds\n","Epoch: 307; Training loss: 0.24840930104255676\n","Epoch: 307; Val loss: 0.3848525583744049\n","Time per epoch: 7.678452014923096 seconds\n","Epoch: 308; Training loss: 0.2434772551059723\n","Epoch: 308; Val loss: 0.42853420972824097\n","Time per epoch: 7.649092197418213 seconds\n","Epoch: 309; Training loss: 0.2516164779663086\n","Epoch: 309; Val loss: 0.4217941164970398\n","Time per epoch: 7.670886993408203 seconds\n","Epoch: 310; Training loss: 0.2444097399711609\n","Epoch: 310; Val loss: 0.4294736087322235\n","Time per epoch: 7.85191535949707 seconds\n","Epoch: 311; Training loss: 0.24532848596572876\n","Epoch: 311; Val loss: 0.40152180194854736\n","Time per epoch: 7.8247222900390625 seconds\n","Epoch: 312; Training loss: 0.2520647943019867\n","Epoch: 312; Val loss: 0.455188125371933\n","Time per epoch: 7.649276971817017 seconds\n","Epoch: 313; Training loss: 0.2508668303489685\n","Epoch: 313; Val loss: 0.4098081886768341\n","Time per epoch: 7.672426462173462 seconds\n","Epoch: 314; Training loss: 0.24555286765098572\n","Epoch: 314; Val loss: 0.40119656920433044\n","Time per epoch: 7.649932861328125 seconds\n","Epoch: 315; Training loss: 0.25135567784309387\n","Epoch: 315; Val loss: 0.4056452512741089\n","Time per epoch: 7.883961915969849 seconds\n","Epoch: 316; Training loss: 0.24774664640426636\n","Epoch: 316; Val loss: 0.3910694718360901\n","Time per epoch: 7.808319091796875 seconds\n","Epoch: 317; Training loss: 0.25403741002082825\n","Epoch: 317; Val loss: 0.417732834815979\n","Time per epoch: 7.6719396114349365 seconds\n","Epoch: 318; Training loss: 0.25066280364990234\n","Epoch: 318; Val loss: 0.41739460825920105\n","Time per epoch: 7.650667190551758 seconds\n","Epoch: 319; Training loss: 0.2544211149215698\n","Epoch: 319; Val loss: 0.44943705201148987\n","Time per epoch: 7.674622058868408 seconds\n","Epoch: 320; Training loss: 0.2392352670431137\n","Epoch: 320; Val loss: 0.4294373095035553\n","Time per epoch: 7.649276971817017 seconds\n","Epoch: 321; Training loss: 0.24849361181259155\n","Epoch: 321; Val loss: 0.4223642349243164\n","Time per epoch: 7.8500049114227295 seconds\n","Epoch: 322; Training loss: 0.2454332411289215\n","Epoch: 322; Val loss: 0.4348512291908264\n","Time per epoch: 7.649163722991943 seconds\n","Epoch: 323; Training loss: 0.24563677608966827\n","Epoch: 323; Val loss: 0.4180667996406555\n","Time per epoch: 7.835317611694336 seconds\n","Epoch: 324; Training loss: 0.2538147270679474\n","Epoch: 324; Val loss: 0.4071723520755768\n","Time per epoch: 7.650768041610718 seconds\n","Epoch: 325; Training loss: 0.2420666515827179\n","Epoch: 325; Val loss: 0.41854023933410645\n","Time per epoch: 7.675338268280029 seconds\n","Epoch: 326; Training loss: 0.2475694715976715\n","Epoch: 326; Val loss: 0.4265216290950775\n","Time per epoch: 7.649522304534912 seconds\n","Epoch: 327; Training loss: 0.23570537567138672\n","Epoch: 327; Val loss: 0.4145769476890564\n","Time per epoch: 7.670612335205078 seconds\n","Epoch: 328; Training loss: 0.2442622035741806\n","Epoch: 328; Val loss: 0.4149421751499176\n","Time per epoch: 7.83222770690918 seconds\n","Epoch: 329; Training loss: 0.2503427565097809\n","Epoch: 329; Val loss: 0.3939014673233032\n","Time per epoch: 7.672494888305664 seconds\n","Epoch: 330; Training loss: 0.24600578844547272\n","Epoch: 330; Val loss: 0.42284536361694336\n","Time per epoch: 7.753885507583618 seconds\n","Epoch: 331; Training loss: 0.25091269612312317\n","Epoch: 331; Val loss: 0.42181891202926636\n","Time per epoch: 7.673887729644775 seconds\n","Epoch: 332; Training loss: 0.2511783242225647\n","Epoch: 332; Val loss: 0.4091208875179291\n","Time per epoch: 7.641824960708618 seconds\n","Epoch: 333; Training loss: 0.24542507529258728\n","Epoch: 333; Val loss: 0.41215139627456665\n","Time per epoch: 7.844909906387329 seconds\n","Epoch: 334; Training loss: 0.25519710779190063\n","Epoch: 334; Val loss: 0.41465282440185547\n","Time per epoch: 7.648248195648193 seconds\n","Epoch: 335; Training loss: 0.24641722440719604\n","Epoch: 335; Val loss: 0.40896859765052795\n","Time per epoch: 7.700588703155518 seconds\n","Epoch: 336; Training loss: 0.2524128258228302\n","Epoch: 336; Val loss: 0.4202115535736084\n","Time per epoch: 7.6468260288238525 seconds\n","Epoch: 337; Training loss: 0.24123618006706238\n","Epoch: 337; Val loss: 0.4188227653503418\n","Time per epoch: 7.674696207046509 seconds\n","Epoch: 338; Training loss: 0.24429260194301605\n","Epoch: 338; Val loss: 0.41198763251304626\n","Time per epoch: 7.847638368606567 seconds\n","Epoch: 339; Training loss: 0.2491976022720337\n","Epoch: 339; Val loss: 0.39519238471984863\n","Time per epoch: 7.858278512954712 seconds\n","Epoch: 340; Training loss: 0.23767177760601044\n","Epoch: 340; Val loss: 0.39910072088241577\n","Time per epoch: 7.6497087478637695 seconds\n","Epoch: 341; Training loss: 0.23743940889835358\n","Epoch: 341; Val loss: 0.4120015799999237\n","Time per epoch: 7.670089483261108 seconds\n","Epoch: 342; Training loss: 0.23893268406391144\n","Epoch: 342; Val loss: 0.39576369524002075\n","Time per epoch: 7.6507580280303955 seconds\n","Epoch: 343; Training loss: 0.2451927810907364\n","Epoch: 343; Val loss: 0.4016770124435425\n","Time per epoch: 7.673424959182739 seconds\n","Epoch: 344; Training loss: 0.24853011965751648\n","Epoch: 344; Val loss: 0.41639789938926697\n","Time per epoch: 7.65191650390625 seconds\n","Epoch: 345; Training loss: 0.24627795815467834\n","Epoch: 345; Val loss: 0.3841492235660553\n","Time per epoch: 7.859341144561768 seconds\n","Epoch: 346; Training loss: 0.2378620058298111\n","Epoch: 346; Val loss: 0.4396953582763672\n","Time per epoch: 7.797508716583252 seconds\n","Epoch: 347; Training loss: 0.239664226770401\n","Epoch: 347; Val loss: 0.42080891132354736\n","Time per epoch: 7.669907093048096 seconds\n","Epoch: 348; Training loss: 0.2353072613477707\n","Epoch: 348; Val loss: 0.406485915184021\n","Time per epoch: 7.648893117904663 seconds\n","Epoch: 349; Training loss: 0.23561698198318481\n","Epoch: 349; Val loss: 0.4043836295604706\n","Time per epoch: 7.675821781158447 seconds\n","Epoch: 350; Training loss: 0.24396328628063202\n","Epoch: 350; Val loss: 0.43722572922706604\n","Time per epoch: 7.827782392501831 seconds\n","Epoch: 351; Training loss: 0.24251234531402588\n","Epoch: 351; Val loss: 0.4039924144744873\n","Time per epoch: 7.670900583267212 seconds\n","Epoch: 352; Training loss: 0.2338859587907791\n","Epoch: 352; Val loss: 0.39808911085128784\n","Time per epoch: 7.831949949264526 seconds\n","Epoch: 353; Training loss: 0.25077688694000244\n","Epoch: 353; Val loss: 0.4301995038986206\n","Time per epoch: 7.6733996868133545 seconds\n","Epoch: 354; Training loss: 0.24379299581050873\n","Epoch: 354; Val loss: 0.3975839614868164\n","Time per epoch: 7.644182443618774 seconds\n","Epoch: 355; Training loss: 0.23784835636615753\n","Epoch: 355; Val loss: 0.4086169898509979\n","Time per epoch: 7.669579267501831 seconds\n","Epoch: 356; Training loss: 0.2388097643852234\n","Epoch: 356; Val loss: 0.39344048500061035\n","Time per epoch: 7.8122475147247314 seconds\n","Epoch: 357; Training loss: 0.24033446609973907\n","Epoch: 357; Val loss: 0.3937813937664032\n","Time per epoch: 7.6723809242248535 seconds\n","Epoch: 358; Training loss: 0.24354587495326996\n","Epoch: 358; Val loss: 0.4210585653781891\n","Time per epoch: 7.73447060585022 seconds\n","Epoch: 359; Training loss: 0.23588117957115173\n","Epoch: 359; Val loss: 0.43891817331314087\n","Time per epoch: 7.675261735916138 seconds\n","Epoch: 360; Training loss: 0.23498591780662537\n","Epoch: 360; Val loss: 0.4044288098812103\n","Time per epoch: 7.676329851150513 seconds\n","Epoch: 361; Training loss: 0.23200802505016327\n","Epoch: 361; Val loss: 0.4226333796977997\n","Time per epoch: 7.67218017578125 seconds\n","Epoch: 362; Training loss: 0.24138149619102478\n","Epoch: 362; Val loss: 0.3929358720779419\n","Time per epoch: 7.648243188858032 seconds\n","Epoch: 363; Training loss: 0.2459188848733902\n","Epoch: 363; Val loss: 0.42419740557670593\n","Time per epoch: 7.832097768783569 seconds\n","Epoch: 364; Training loss: 0.23684746026992798\n","Epoch: 364; Val loss: 0.4079302251338959\n","Time per epoch: 7.647222995758057 seconds\n","Epoch: 365; Training loss: 0.2350129634141922\n","Epoch: 365; Val loss: 0.38741379976272583\n","Time per epoch: 7.690097093582153 seconds\n","Epoch: 366; Training loss: 0.23296374082565308\n","Epoch: 366; Val loss: 0.40771761536598206\n","Time per epoch: 7.650343894958496 seconds\n","Epoch: 367; Training loss: 0.2397453337907791\n","Epoch: 367; Val loss: 0.4241633117198944\n","Time per epoch: 7.867046356201172 seconds\n","Epoch: 368; Training loss: 0.2281692773103714\n","Epoch: 368; Val loss: 0.41648149490356445\n","Time per epoch: 7.807229518890381 seconds\n","Epoch: 369; Training loss: 0.22925497591495514\n","Epoch: 369; Val loss: 0.42853492498397827\n","Time per epoch: 7.6720287799835205 seconds\n","Epoch: 370; Training loss: 0.2416764795780182\n","Epoch: 370; Val loss: 0.39714378118515015\n","Time per epoch: 7.651761770248413 seconds\n","Epoch: 371; Training loss: 0.23499846458435059\n","Epoch: 371; Val loss: 0.4222720265388489\n","Time per epoch: 7.673494815826416 seconds\n","Epoch: 372; Training loss: 0.24046145379543304\n","Epoch: 372; Val loss: 0.3968088626861572\n","Time per epoch: 7.648914813995361 seconds\n","Epoch: 373; Training loss: 0.24496565759181976\n","Epoch: 373; Val loss: 0.3862825036048889\n","Time per epoch: 7.870354175567627 seconds\n","Epoch: 374; Training loss: 0.23473651707172394\n","Epoch: 374; Val loss: 0.397624671459198\n","Time per epoch: 7.7936177253723145 seconds\n","Epoch: 375; Training loss: 0.23011621832847595\n","Epoch: 375; Val loss: 0.43050524592399597\n","Time per epoch: 7.671608209609985 seconds\n","Epoch: 376; Training loss: 0.22918537259101868\n","Epoch: 376; Val loss: 0.3933778703212738\n","Time per epoch: 7.648932456970215 seconds\n","Epoch: 377; Training loss: 0.2345966398715973\n","Epoch: 377; Val loss: 0.4264310598373413\n","Time per epoch: 7.673339605331421 seconds\n","Epoch: 378; Training loss: 0.22918082773685455\n","Epoch: 378; Val loss: 0.40209490060806274\n","Time per epoch: 7.653259992599487 seconds\n","Epoch: 379; Training loss: 0.22787459194660187\n","Epoch: 379; Val loss: 0.4216596186161041\n","Time per epoch: 7.673842668533325 seconds\n","Epoch: 380; Training loss: 0.23024918138980865\n","Epoch: 380; Val loss: 0.42714810371398926\n","Time per epoch: 7.829965353012085 seconds\n","Epoch: 381; Training loss: 0.23370102047920227\n","Epoch: 381; Val loss: 0.41129305958747864\n","Time per epoch: 7.670217752456665 seconds\n","Epoch: 382; Training loss: 0.22975780069828033\n","Epoch: 382; Val loss: 0.40645092725753784\n","Time per epoch: 7.820729732513428 seconds\n","Epoch: 383; Training loss: 0.24149085581302643\n","Epoch: 383; Val loss: 0.42133066058158875\n","Time per epoch: 7.672566175460815 seconds\n","Epoch: 384; Training loss: 0.2476716935634613\n","Epoch: 384; Val loss: 0.4223887324333191\n","Time per epoch: 7.646291732788086 seconds\n","Epoch: 385; Training loss: 0.23926123976707458\n","Epoch: 385; Val loss: 0.42130792140960693\n","Time per epoch: 7.837445974349976 seconds\n","Epoch: 386; Training loss: 0.23810707032680511\n","Epoch: 386; Val loss: 0.4032532572746277\n","Time per epoch: 7.650527000427246 seconds\n","Epoch: 387; Training loss: 0.2304028570652008\n","Epoch: 387; Val loss: 0.4279211163520813\n","Time per epoch: 7.76781964302063 seconds\n","Epoch: 388; Training loss: 0.23490940034389496\n","Epoch: 388; Val loss: 0.4416532516479492\n","Time per epoch: 7.649815082550049 seconds\n","Epoch: 389; Training loss: 0.22743885219097137\n","Epoch: 389; Val loss: 0.3862263262271881\n","Time per epoch: 7.675459861755371 seconds\n","Epoch: 390; Training loss: 0.22760643064975739\n","Epoch: 390; Val loss: 0.3923474848270416\n","Time per epoch: 7.84214186668396 seconds\n","Epoch: 391; Training loss: 0.2306484878063202\n","Epoch: 391; Val loss: 0.4423346519470215\n","Time per epoch: 7.835999011993408 seconds\n","Epoch: 392; Training loss: 0.24039645493030548\n","Epoch: 392; Val loss: 0.4229051172733307\n","Time per epoch: 7.647592067718506 seconds\n","Epoch: 393; Training loss: 0.229159876704216\n","Epoch: 393; Val loss: 0.3879702091217041\n","Time per epoch: 7.671225309371948 seconds\n","Epoch: 394; Training loss: 0.23655767738819122\n","Epoch: 394; Val loss: 0.40872305631637573\n","Time per epoch: 7.651337385177612 seconds\n","Epoch: 395; Training loss: 0.22721022367477417\n","Epoch: 395; Val loss: 0.4259554445743561\n","Time per epoch: 7.673390626907349 seconds\n","Epoch: 396; Training loss: 0.23383086919784546\n","Epoch: 396; Val loss: 0.4208905100822449\n","Time per epoch: 7.651286363601685 seconds\n","Epoch: 397; Training loss: 0.22995413839817047\n","Epoch: 397; Val loss: 0.39393168687820435\n","Time per epoch: 7.857733726501465 seconds\n","Epoch: 398; Training loss: 0.232564315199852\n","Epoch: 398; Val loss: 0.39506804943084717\n","Time per epoch: 7.801945686340332 seconds\n","Epoch: 399; Training loss: 0.23478636145591736\n","Epoch: 399; Val loss: 0.44597429037094116\n","Time per epoch: 7.671682834625244 seconds\n","Epoch: 400; Training loss: 0.22983615100383759\n","Epoch: 400; Val loss: 0.43302932381629944\n","Time per epoch: 7.650064468383789 seconds\n","Epoch: 401; Training loss: 0.22686587274074554\n","Epoch: 401; Val loss: 0.3918745517730713\n","Time per epoch: 7.662294387817383 seconds\n","Epoch: 402; Training loss: 0.2240913361310959\n","Epoch: 402; Val loss: 0.4113989472389221\n","Time per epoch: 7.8341498374938965 seconds\n","Epoch: 403; Training loss: 0.2283267080783844\n","Epoch: 403; Val loss: 0.40481698513031006\n","Time per epoch: 7.812324285507202 seconds\n","Epoch: 404; Training loss: 0.23027458786964417\n","Epoch: 404; Val loss: 0.41747501492500305\n","Time per epoch: 7.649999141693115 seconds\n","Epoch: 405; Training loss: 0.23211851716041565\n","Epoch: 405; Val loss: 0.400797575712204\n","Time per epoch: 7.6741557121276855 seconds\n","Epoch: 406; Training loss: 0.23494715988636017\n","Epoch: 406; Val loss: 0.41021934151649475\n","Time per epoch: 7.6497414112091064 seconds\n","Epoch: 407; Training loss: 0.2299681156873703\n","Epoch: 407; Val loss: 0.40870222449302673\n","Time per epoch: 7.676944255828857 seconds\n","Epoch: 408; Training loss: 0.23425224423408508\n","Epoch: 408; Val loss: 0.4255825877189636\n","Time per epoch: 7.829412221908569 seconds\n","Epoch: 409; Training loss: 0.2355269491672516\n","Epoch: 409; Val loss: 0.4084819257259369\n","Time per epoch: 7.672008514404297 seconds\n","Epoch: 410; Training loss: 0.22877906262874603\n","Epoch: 410; Val loss: 0.4500997066497803\n","Time per epoch: 7.770174741744995 seconds\n","Epoch: 411; Training loss: 0.22685755789279938\n","Epoch: 411; Val loss: 0.3935883641242981\n","Time per epoch: 7.674833536148071 seconds\n","Epoch: 412; Training loss: 0.24590331315994263\n","Epoch: 412; Val loss: 0.4278233051300049\n","Time per epoch: 7.650954246520996 seconds\n","Epoch: 413; Training loss: 0.2387513369321823\n","Epoch: 413; Val loss: 0.4112599790096283\n","Time per epoch: 7.673030138015747 seconds\n","Epoch: 414; Training loss: 0.23014377057552338\n","Epoch: 414; Val loss: 0.3944860100746155\n","Time per epoch: 7.647321462631226 seconds\n","Epoch: 415; Training loss: 0.2309340238571167\n","Epoch: 415; Val loss: 0.39736661314964294\n","Time per epoch: 7.85961651802063 seconds\n","Epoch: 416; Training loss: 0.23153185844421387\n"]}]}]}